---
title: "Chapter03"
output:
  github_document: default
  html_notebook: default
---

## 3. "Analyzing word and document frequency: tf-idf"

A central question in text mining and natural language processing is how to quantify what a document is about. ... The statistic 'tf-idf' is intended to measure how important a word is to a document in a collection (or corpus) of documents


### 3.1 Term frequency in Jane Austen’s novels

Let’s start by looking at the published novels of Jane Austen and examine first term frequency, then tf-idf.
```{r}
library(dplyr)
library(janeaustenr)
library(tidytext)

book_words <- austen_books() %>%          # most commonly used words in Jane Austen’s novels
  unnest_tokens(word, text) %>%
  count(book, word, sort = TRUE) %>%
  ungroup()                               # cols : book, word, n

total_words <- book_words %>%             # total words in each novel, for later use
  group_by(book) %>% 
  summarize(total = sum(n))

book_words <- left_join(book_words, total_words)          # cols : book, word, n, total
```


let’s look at the distribution of n/total for each novel ... This is exactly what term frequency is.
```{r}
library(ggplot2)

ggplot(book_words, aes(n/total, fill = book)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~book, ncol = 2, scales = "free_y")
```

...There are very long tails to the right for these novels (those extremely common words!) that we have not shown in these plots



### 3.2 Zipf’s law

Zipf’s law states that the frequency that a word appears is inversely proportional to its rank.
```{r}
freq_by_rank <- book_words %>% 
  group_by(book) %>% 
  mutate(rank = row_number(), `term frequency` = n/total)
```


Zipf’s law is often visualized by plotting rank on the x-axis and term frequency on the y-axis, on logarithmic scales. Plotting this way, an inversely proportional relationship will have a constant, negative slope.
```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = book)) + 
  geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +    # by lin/regression
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

...The deviations we see here at high rank are not uncommon ... The deviations at low rank are more unusual.



### 3.3 The `bind_tf_idf` function

Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common.
```{r}
book_words <- book_words %>%
  bind_tf_idf(word, book, n)      # tidy text dataset as input with one row per token, per document.
```


Let’s look at terms with high tf-idf in Jane Austen’s works.
```{r}
book_words %>%
  select(-total) %>%
  arrange(desc(tf_idf))
```


```{r}
book_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(book) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = book)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~book, ncol = 2, scales = "free") +
  coord_flip()
```

...Jane Austen used similar language across her six novels, and what distinguishes one novel from the rest within the collection of her works are the proper nouns, the names of people and places.



### 3.4 A corpus of physics texts

Let’s download some classic physics texts from Project Gutenberg and see what terms are important in these works, as measured by tf-idf.
```{r}
library(gutenbergr)
physics <- gutenberg_download(c(37729, 14725, 13476, 5001), 
                              meta_fields = "author")
```


let’s use unnest_tokens() and count() to find out how many times each word was used in each text.
```{r}
physics_words <- physics %>%
  unnest_tokens(word, text) %>%
  count(author, word, sort = TRUE) %>%
  ungroup()
```


we need to remember that these documents are all different lengths. Let’s go ahead and calculate tf-idf, then visualize the high tf-idf words
```{r}
plot_physics <- physics_words %>%
  bind_tf_idf(word, author, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  mutate(author = factor(author, levels = c("Galilei, Galileo",
                                            "Huygens, Christiaan", 
                                            "Tesla, Nikola",
                                            "Einstein, Albert")))

plot_physics %>% 
  group_by(author) %>% 
  top_n(15, tf_idf) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = author)) +                           # visualize
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()
```

...Some cleaning up of the text may be in order. ...[make a custom list of stop words and use `anti_join()` to remove them]



### 3.5 Summary

