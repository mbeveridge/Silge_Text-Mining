---
title: "Chapter01"
output:
  github_document: default
  html_notebook: default
---

## 1. "The Tidy Text Format"
### 1.1 Contrasting tidy text with other data structures
### 1.2 The `unnest_tokens` function

Emily Dickinson wrote some lovely text in her time.
```{r}
text <- c("Because I could not stop for Death -",
          "He kindly stopped for me -",
          "The Carriage held but just Ourselves -",
          "and Immortality")

text
```


This is a typical character vector that we might want to analyze. In order to turn it into a tidy text dataset, we first need to put it into a data frame.
```{r}
library(dplyr)
text_df <- data_frame(line = 1:4, text = text)

text_df
```


Within our tidy text framework, we need to both break the text into individual tokens and transform it to a tidy data structure. To do this, we use tidytext’s `unnest_tokens()` function.
```{r}
library(tidytext)

text_df %>%
  unnest_tokens(word, text)
```



### 1.3 Tidying the works of Jane Austen

Let’s use the text of Jane Austen’s 6 completed, published novels ... and also use `mutate()` to annotate a `linenumber` quantity to keep track of lines in the original format and a `chapter` (using a regex)
```{r}
library(janeaustenr)
library(dplyr)
library(stringr)

original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                 ignore_case = TRUE)))) %>%
  ungroup()      # [Remind myself how this works]

original_books
```


To work with this as a tidy dataset, we need to restructure it in the one-token-per-row format
```{r}
library(tidytext)
tidy_books <- original_books %>%
  unnest_tokens(word, text)

tidy_books
```


We can remove stop words (kept in the tidytext dataset `stop_words`) with an `anti_join()`.
```{r}
data(stop_words)         # "Loads specified data sets, or list the available data sets"
                         # [https://stat.ethz.ch/R-manual/R-devel/library/utils/html/data.html]

tidy_books <- tidy_books %>%
  anti_join(stop_words)
```


We can also use dplyr’s `count()` to find the most common words in all the books as a whole.
```{r}
tidy_books %>%
  count(word, sort = TRUE)
```


our word counts are stored in a tidy data frame ... for example to create a visualization of the most common words
```{r}
library(ggplot2)

tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

...`austen_books()` function started us with exactly the text we wanted to analyze, but in other cases we may need to perform cleaning of text data, such as removing copyright headers or formatting.



### 1.4 The gutenbergr package

https://stackoverflow.com/questions/34705917/conda-how-to-install-r-packages-that-are-not-available-in-r-essentials

`> install.packages("gutenbergr", "~/anaconda3/lib/R/library")
also installing the dependencies ‘triebeard’, ‘urltools’`



### 1.5 Word frequencies

A common task in text mining is to look at word frequencies, just like we have done above for Jane Austen’s novels, ... let’s get two more sets of texts to compare to. ... We can access these works using `gutenberg_download()` and the Project Gutenberg ID numbers for each novel.
```{r}
library(gutenbergr)

hgwells <- gutenberg_download(c(35, 36, 5230, 159))

tidy_hgwells <- hgwells %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_hgwells %>%
  count(word, sort = TRUE)
```


Now let’s get some well-known works of the Brontë sisters
```{r}
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))

tidy_bronte <- bronte %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_bronte %>%
  count(word, sort = TRUE)
```


Now, let’s calculate the frequency for each word for the works of Jane Austen, the Brontë sisters, and H.G. Wells by binding the data frames together.
```{r}
library(tidyr)

frequency <- bind_rows(mutate(tidy_bronte, author = "Brontë Sisters"),      # `mutate()` adds new col
                       mutate(tidy_hgwells, author = "H.G. Wells"), 
                       mutate(tidy_books, author = "Jane Austen")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%            # `str_extract()` excludes underscores
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>%                        # `proportion` ...grouped by `author`
  select(-n) %>%                      # cols : `author`, `word`, `proportion`
  spread(author, proportion) %>%      # cols : `word`, `Brontë Sisters`, `H.G. Wells`, `Jane Austen`
  gather(author, proportion, `Brontë Sisters`:`H.G. Wells`)      # cols : `word`, `Jane Austen`, `author`, `proportion`
```


Now let’s plot ...[MB: y = `Jane Austen`, below, uses `Jane Austen` col from `gather()`, above]
```{r}
library(scales)

ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  #geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  #scale_x_log10(labels = percent_format()) +
  #scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Jane Austen", x = NULL)
```


### 1.6 Summary


